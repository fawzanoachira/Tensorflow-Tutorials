{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZfhEKJFCo6DjVIoBsYDU7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Convolutional Neural Networks (CNNs)**\n","\n","###**Introduction to CNNs**\n","\n","Convolutional Neural Networks (CNNs) are a class of deep neural networks that are particularly well-suited for tasks such as image recognition and classification. They are inspired by the visual processing of the human brain and are designed to automatically and adaptively learn spatial hierarchies of features from input data.\n","\n","###**Architecture of CNNs:**\n","\n","CNNs typically consist of layers that perform specific operations. The common architecture includes:\n","\n","![CNN Architecture](https://miro.medium.com/v2/resize:fit:720/format:webp/0*uo_4mk0hTHK77o7V.png)"],"metadata":{"id":"70lav9h0zAWI"}},{"cell_type":"markdown","source":["###**Layers in CNNs:**\n","\n",">**Convolutional Layers:** These layers apply convolutional operations to the input, using filters to extract important features.\n","\n",">**Pooling Layers:** Pooling layers reduce the spatial dimensions of the feature maps.\n","\n",">**Fully Connected Layers:** These layers connect\n","every neuron in one layer to every neuron in the\n","next layer, allowing the network to make predictions.\n","\n","\n","\n","\n","###**Filters in CNNs:**\n","\n","Filters (or kernels) are small-sized matrices that are used to extract features from the input data.\n","Convolutional layers use multiple filters to detect different patterns in the input.\n","\n","###**Activation Functions:**\n","\n",">**ReLU (Rectified Linear Unit):** The most commonly used activation function, ReLU replaces all negative pixel values in the feature map with zero.\n","\n",">**Leaky ReLU:** A modified version of ReLU that allows a small, positive gradient for negative inputs, preventing dead neurons.\n","\n","\n","---\n","\n"],"metadata":{"id":"l7Wq3_sk0Q1E"}},{"cell_type":"markdown","source":["#**Convolutional Operations and Pooling Layers in CNNs**\n","##**1. Convolutional Operations**\n","###Padding:\n","\n","Padding is a technique used to preserve the spatial dimensions of the input image after convolution operations on a feature map. Padding involves adding extra pixels around the border of the input feature map before convolution. <br><br>\n","\n","This can be done in two ways:\n","\n","> **Valid Padding:** In the valid padding, no padding is added to the input feature map, and the output feature map is smaller than the input feature map. This is useful when we want to reduce the spatial dimensions of the feature maps.\n","\n",">**Same Padding:** In the same padding, padding is added to the input feature map such that the size of the output feature map is the same as the input feature map. This is useful when we want to preserve the spatial dimensions of the feature maps.<br><br>\n","The number of pixels to be added for padding can be calculated based on the size of the kernel and the desired output of the feature map size. The most common padding value is zero-padding, which involves adding zeros to the borders of the input feature map.\n","\n","Padding can help in reducing the loss of information at the borders of the input feature map and can improve the performance of the model. However, it also increases the computational cost of the convolution operation. Overall, padding is an important technique in CNNs that helps in preserving the spatial dimensions of the feature maps and can improve the performance of the model."],"metadata":{"id":"N2dwmxQUYTze"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Create a sample 2D tensor (e.g., an image)\n","input_tensor = tf.constant([[1, 2, 3],\n","                            [4, 5, 6],\n","                            [7, 8, 9]])\n","\n","# Specify the padding sizes for each dimension (height, width)\n","padding_sizes = [[1, 1], [1, 1]]\n","\n","# Apply zero-padding to the tensor\n","padded_tensor = tf.pad(input_tensor, padding_sizes, \"CONSTANT\")\n","\n","# Print the original and padded tensors\n","print(\"Original Tensor:\")\n","print(input_tensor)\n","print(\"\\nPadded Tensor:\")\n","print(padded_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwnxyWqEJUxY","executionInfo":{"status":"ok","timestamp":1704534057267,"user_tz":-330,"elapsed":3689,"user":{"displayName":"Fawzan ICFOSS","userId":"12962120267022142144"}},"outputId":"6e734d2f-2830-44e5-f2b3-bd3cd0e6c08f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Tensor:\n","tf.Tensor(\n","[[1 2 3]\n"," [4 5 6]\n"," [7 8 9]], shape=(3, 3), dtype=int32)\n","\n","Padded Tensor:\n","tf.Tensor(\n","[[0 0 0 0 0]\n"," [0 1 2 3 0]\n"," [0 4 5 6 0]\n"," [0 7 8 9 0]\n"," [0 0 0 0 0]], shape=(5, 5), dtype=int32)\n"]}]},{"cell_type":"markdown","source":["###Strides:\n","Stride is a parameter that dictates the movement of the kernel, or filter, across the input data, such as an image. When performing a convolution operation, the stride determines how many units the filter shifts at each step. This shift can be horizontal, vertical, or both, depending on the stride's configuration.<br><br>\n",">For example, a stride of 1 moves the filter one pixel at a time, while a stride of 2 moves it two pixels. A larger stride will produce a smaller output dimension, effectively downsampling the image."],"metadata":{"id":"6HCFpWMMZJ2d"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# Create a sample 4D tensor (batch_size, height, width, channels)\n","input_tensor = tf.constant(np.random.randn(1, 5, 5, 3), dtype=tf.float32)\n","\n","# Define the convolutional layer with a specific stride\n","conv_layer = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(2, 2), padding='valid', activation='relu')\n","\n","# Apply the convolutional layer to the input tensor\n","output_tensor = conv_layer(input_tensor)\n","\n","# Print the shapes of the input and output tensors\n","print(\"Input Tensor Shape:\", input_tensor.shape)\n","print(\"Output Tensor Shape:\", output_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6OWggTZJ3Ns","executionInfo":{"status":"ok","timestamp":1704534550066,"user_tz":-330,"elapsed":9,"user":{"displayName":"Fawzan ICFOSS","userId":"12962120267022142144"}},"outputId":"6bd53289-19b5-4695-e3e9-b0cd0a229711"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Tensor Shape: (1, 5, 5, 3)\n","Output Tensor Shape: (1, 2, 2, 16)\n"]}]},{"cell_type":"markdown","source":["###Dilation:\n","Dilated Convolution: It is a technique that expands the kernel (input) by inserting holes between its consecutive elements. In simpler terms, it is the same as convolution but it involves pixel skipping, so as to cover a larger area of the input.<br><br>\n","Dilated convolution, also known as atrous convolution, is a type of convolution operation used in convolutional neural networks (CNNs) that enables the network to have a larger receptive field without increasing the number of parameters."],"metadata":{"id":"CIBadcZcJR2Q"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Create a sample 4D tensor (batch_size, height, width, channels)\n","input_tensor = tf.constant([[1, 2, 3],\n","                            [4, 5, 6],\n","                            [7, 8, 9]], dtype=tf.float32)\n","\n","# Reshape the tensor to have batch and channel dimensions\n","input_tensor = tf.reshape(input_tensor, (1, 3, 3, 1))\n","\n","# Define the convolutional layer with dilation\n","conv_layer = tf.keras.layers.Conv2D(filters=1, kernel_size=(2, 2), dilation_rate=(2, 2), padding='valid', activation='relu')\n","\n","# Apply the convolutional layer to the input tensor\n","output_tensor = conv_layer(input_tensor)\n","\n","# Print the shapes of the input and output tensors\n","print(\"Input Tensor Shape:\", input_tensor.shape)\n","print(\"Output Tensor Shape:\", output_tensor.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_5uyjBrULhbo","executionInfo":{"status":"ok","timestamp":1704534620096,"user_tz":-330,"elapsed":11,"user":{"displayName":"Fawzan ICFOSS","userId":"12962120267022142144"}},"outputId":"eaba8b7e-0a1d-4c24-8f21-09bd0618f6f2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Tensor Shape: (1, 3, 3, 1)\n","Output Tensor Shape: (1, 1, 1, 1)\n"]}]},{"cell_type":"markdown","source":["##**2. Pooling Layers**\n","The pooling operation involves sliding a two-dimensional filter over each channel of feature map and summarising the features lying within the region covered by the filter.\n","<br><br>\n","Types of Pooling Layers:\n","###Max Pooling:\n","Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map.\n","![picture](https://media.geeksforgeeks.org/wp-content/uploads/20190721025744/Screenshot-2019-07-21-at-2.57.13-AM.png)\n","\n","###Average Pooling:\n","\n","Average pooling computes the average of the elements present in the region of feature map covered by the filter. Thus, while max pooling gives the most prominent feature in a particular patch of the feature map, average pooling gives the average of features present in a patch.\n","![picture](https://media.geeksforgeeks.org/wp-content/uploads/20190721030705/Screenshot-2019-07-21-at-3.05.56-AM.png)"],"metadata":{"id":"9Q5OuFSHJ0AN"}},{"cell_type":"markdown","source":["Max Pooling"],"metadata":{"id":"FFxBD4TdMCBd"}},{"cell_type":"code","source":["x = tf.constant([[1., 2., 3.],\n","                 [4., 5., 6.],\n","                 [7., 8., 9.]])\n","x = tf.reshape(x, [1, 3, 3, 1])\n","max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n","   strides=(1, 1), padding='valid')\n","max_pool_2d(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmawWWirL95a","executionInfo":{"status":"ok","timestamp":1704534736694,"user_tz":-330,"elapsed":791,"user":{"displayName":"Fawzan ICFOSS","userId":"12962120267022142144"}},"outputId":"6c876fcf-3ff7-4ed4-b3e6-c68f6445b640"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n","array([[[[5.],\n","         [6.]],\n","\n","        [[8.],\n","         [9.]]]], dtype=float32)>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["x = tf.constant([[1., 2., 3.],\n","                 [4., 5., 6.],\n","                 [7., 8., 9.]])\n","x = tf.reshape(x, [1, 3, 3, 1])\n","avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n","   strides=(1, 1), padding='valid')\n","avg_pool_2d(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c3xfT9zL_dv","executionInfo":{"status":"ok","timestamp":1704534822648,"user_tz":-330,"elapsed":10,"user":{"displayName":"Fawzan ICFOSS","userId":"12962120267022142144"}},"outputId":"6f2bbe1b-63a6-4779-f4d9-79cf429812f4"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n","array([[[[3.],\n","         [4.]],\n","\n","        [[6.],\n","         [7.]]]], dtype=float32)>"]},"metadata":{},"execution_count":12}]}]}